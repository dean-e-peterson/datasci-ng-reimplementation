{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Andrew Ng Coursera Machine Learning Course - Ex 2\n",
    "**Dean's Reimplementation Attempt**\n",
    "\n",
    "*8/19/2017*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: See [here](https://docs.scipy.org/doc/scipy/reference/api.html#guidelines-for-importing-functions-from-scipy) for recommendations on how to import `scipy` modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression\n",
    "**Note:** This is a classification algorithm, despite the term \"regression\" in the name.  Classification means outputs $y$ take on discrete values, for example $y \\in \\{0,1\\}$.  The output is  also known as a *label*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Sigmoid function*, aka *logistic function*\n",
    "\n",
    "$$ g(z) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1ecfa54a400>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlYAAAB0CAYAAABHXnwLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nShSsRERERKpEwUpERESkSv4/QbkCw+YO1V4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ecfa4ccb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "z = np.arange(-4, 4.01, .1)\n",
    "g = 1 / (1 + np.exp(-z))\n",
    "plt.figure(figsize=(10, 1.5))\n",
    "plt.plot(z, g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the hypothesis, use:\n",
    "\n",
    "$$z = \\theta^Tx$$\n",
    "\n",
    "$$h_\\theta(x) = g(z) = g(\\theta^Tx) = \\frac{1}{1 + e^{-\\theta^Tx}} $$\n",
    "\n",
    "... making $h_\\theta(x)$ the probability that the output is 1, not 0.\n",
    "\n",
    "$$h_\\theta(x) = P(y=1 \\: | \\: x;\\theta) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the decision boundary, if $h_\\theta(x) \\ge 0.5$, predict $y = 1$.  This happens when $z \\ge 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the cost function, use:\n",
    "\n",
    "$$\\text{Cost}(h_\\theta(x), y) = - \\log_e(h_\\theta(x)) \\qquad\\qquad \\text{if} \\, y=1 $$\n",
    "$$\\text{Cost}(h_\\theta(x), y) = - \\log_e(1 - h_\\theta(x)) \\qquad \\text{if} \\, y=0 $$\n",
    "$$J(\\theta) = \\frac{1}{m} \\sum_{i=1}^m \\text{Cost}\\left(h_\\theta(x^{(i)}, y^{(i)}\\right) $$\n",
    "\n",
    "...so...\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ \n",
    "y^{(i)} \\log(h_\\theta(x^{(i)}))\n",
    "+ (1-y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))\n",
    "\\right] $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorized, this is:\n",
    "$$J(\\theta) = \\frac{1}{m} \\left( -y^\\top\\log(h) - (1-y)^\\top\\log(1-h) \\right) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gradient is:\n",
    "$$\\frac{\\partial}{\\partial\\theta_j} = \\frac{1}{m} \\sum_{i=1}^m\n",
    "  \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x_j^{(i)}$$\n",
    "\n",
    "So the gradient descent rule is:\n",
    "\n",
    "$$\\theta_j := \\theta_j - \\frac{\\alpha}{m} \\sum_{i=1}^m\n",
    "  \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x_j^{(i)}$$\n",
    "...which *looks* the same as for linear regression, but remember that $h_\\theta(x^{(i)})$ is the sigmoid function this time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 1.1 Visualizing the data\n",
    "\n",
    "See [numpy.matmul() documentation](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matmul.html) for how a 1-D numpy array is treated by matrix multiplication.  \n",
    "\n",
    "Basically, given vector v and matrix M, in **`v@M`** the v is treated as a row vector, but in **`M@v`** the v is treated as a column vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 3)\n",
      "(100, 2)\n",
      "(100,)\n",
      "[[ 34.62365962  78.02469282   0.        ]\n",
      " [ 30.28671077  43.89499752   0.        ]\n",
      " [ 35.84740877  72.90219803   0.        ]\n",
      " [ 60.18259939  86.3085521    1.        ]\n",
      " [ 79.03273605  75.34437644   1.        ]]\n",
      "[[ 34.62365962  78.02469282]\n",
      " [ 30.28671077  43.89499752]\n",
      " [ 35.84740877  72.90219803]\n",
      " [ 60.18259939  86.3085521 ]\n",
      " [ 79.03273605  75.34437644]]\n",
      "[ 0.  0.  0.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "data = np.loadtxt('ex2/ex2data1.txt', delimiter=',')\n",
    "X = data[:, 0:2]\n",
    "y = data[:, 2]    # y = data[:, 2:3] for 1-column 2-d array.\n",
    "print(data.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "print(data[:5])\n",
    "print(X[:5])\n",
    "print(y[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = np.where(y == 1)\n",
    "neg = np.where(y == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x1ecfb90d5c0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nE4SZmXX0/wH0dgbwvclGuQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ecfb8b6438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X[pos, 0], X[pos, 1], 'k+', label='Admitted')\n",
    "plt.plot(X[neg, 0], X[neg, 1], 'yo', label='Not admitted')\n",
    "#plt.legend() # This was putting one legend entry for each point.\n",
    "plt.xlabel('Exam 1 score')\n",
    "plt.ylabel('Exam 2 score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1.          34.62365962  78.02469282]\n",
      " [  1.          30.28671077  43.89499752]\n",
      " [  1.          35.84740877  72.90219803]\n",
      " [  1.          60.18259939  86.3085521 ]\n",
      " [  1.          79.03273605  75.34437644]]\n"
     ]
    }
   ],
   "source": [
    "# Add the intercept/bias term of all 1's to X.\n",
    "m = X.shape[0]\n",
    "ones = np.ones((m, 1))\n",
    "X = np.hstack((ones, X))\n",
    "print(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1. Warmup exercise: sigmoid function\n",
    "*Sigmoid function*, aka *logistic function*\n",
    "\n",
    "$$ g(z) = \\frac{1}{1 + e^{-z}}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Student implements...\n",
    "def sigmoid(X):\n",
    "    g = 1 / (1 + np.exp(-X))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2. Cost function and gradient\n",
    "\n",
    "$$J(\\theta) = -\\frac{1}{m} \\sum_{i=1}^m \\left[ \n",
    "y^{(i)} \\log(h_\\theta(x^{(i)}))\n",
    "+ (1-y^{(i)}) \\log(1 - h_\\theta(x^{(i)}))\n",
    "\\right] $$\n",
    "\n",
    "$$\\frac{\\partial}{\\partial\\theta_j} = \\frac{1}{m} \\sum_{i=1}^m\n",
    "  \\left( h_\\theta(x^{(i)}) - y^{(i)} \\right) x_j^{(i)}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initial_theta = np.zeros(X.shape[1]) # np.zeros((X.shape[1], 1)), for n x 1 2d array\n",
    "initial_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Student implements...\n",
    "def costFunction(theta, X, y):\n",
    "    m = X.shape[0]\n",
    "    h = sigmoid(X @ theta) # Not theta.T @ X because I wanted samples in rows?\n",
    "\n",
    "    Jsumofones = y.T @ np.log(h) \n",
    "    Jsumofzeros = (1-y).T @ np.log(1-h)\n",
    "    J = (-1/m) * (Jsumofones + Jsumofzeros)\n",
    "    \n",
    "    grad = (1/m) * X.T @ (h - y)\n",
    "\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost, grad = costFunction(initial_theta, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.69314718056\n",
      "[ -0.1        -12.00921659 -11.26284221]\n"
     ]
    }
   ],
   "source": [
    "# Expected 0.693, and [-0.1, -12.0092, -11.2628]\n",
    "print(cost) # Should this be coming out as a scalar, not a 2-d array?\n",
    "print(grad) # Should this be coming out as a 1-d array, not a 2-d array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    }
   ],
   "source": [
    "# Extra parentheses and commas would make the following a column vector.\n",
    "#test_theta = np.array(((-24,), (0.2,), (0.2,)))\n",
    "test_theta = np.array((-24, 0.2, 0.2))\n",
    "print(test_theta.shape)\n",
    "cost, grad = costFunction(test_theta, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.218330193827\n",
      "[ 0.04290299  2.56623412  2.64679737]\n"
     ]
    }
   ],
   "source": [
    "# Expected cost (approx): 0.218\n",
    "# Expected gradients (approx):  0.043, 2.566, 2.647');\n",
    "print(cost) # Should this be coming out as a scalar, not a 2-d array?\n",
    "print(grad) # Should this be coming out as a 1-d array, not a 2-d array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.2.3. Learning parameters using `scipy.optimize.minimize`\n",
    "`scipy.optimize.minimize()` calls back the objective function with only the parameter vector being optimized (in our case, `theta`).  So first we make basically a partial function based on our `costFunction()` that will still accept `theta`, but will fill in `X` and `y` for us.\n",
    "\n",
    "Note: This has to do with partial as a functional programming concept, not partial derivatives.\n",
    "\n",
    "Note2: It would have been nice to do this with the `partial()` function in the `functools` module, but I don't think the original order of parameters allows that, so do it manually, depending on `X` and `y` being in the overall scope (yuk).\n",
    "\n",
    "Note3: Wait, they had to do the same thing with the `@(t) (costFunction(t, X, y))` syntax in octave/Matlab.  Maybe I should just use a python lambda like `optimize.minimize(lambda t: costFunction(t, X, y), ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def costFun(theta):\n",
    "    J, grad = costFunction(theta, X, y)\n",
    "    return J, grad\n",
    "    # return J[0], grad[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-24. ,   0.2,   0.2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extra parentheses and commas would make the following a column vector.\n",
    "#test_theta = np.array(((-24,), (0.2,), (0.2,)))\n",
    "test_theta = np.array((-24, 0.2, 0.2))\n",
    "print(test_theta.shape)\n",
    "cost, grad = costFun(test_theta)\n",
    "test_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.218330193827\n",
      "[ 0.04290299  2.56623412  2.64679737]\n"
     ]
    }
   ],
   "source": [
    "# Expected cost (approx): 0.218\n",
    "# Expected gradients (approx):  0.043, 2.566, 2.647');\n",
    "print(cost) # Should this be coming out as a scalar, not a 2-d array?\n",
    "print(grad) # Should this be coming out as a 1-d array, not a 2-d array?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OK, NOW try minimizing**\n",
    "\n",
    "Note:  Was using `fminunc()` in Matlab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_theta = np.zeros([X.shape[1]])\n",
    "initial_theta = test_theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.203498\n",
      "         Iterations: 16\n",
      "         Function evaluations: 22\n",
      "         Gradient evaluations: 22\n",
      "Wall time: 12 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result = optimize.minimize(\n",
    "    costFun, #lambda t: costFunction(t, X, y), \n",
    "    initial_theta, \n",
    "    jac=True, \n",
    "    options={'maxiter':100, 'disp':True}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "      fun: 0.2034977015894421\n",
       " hess_inv: array([[  3.33350099e+03,  -2.66055767e+01,  -2.69764676e+01],\n",
       "       [ -2.66055767e+01,   2.27032698e-01,   2.02191103e-01],\n",
       "       [ -2.69764676e+01,   2.02191103e-01,   2.33923485e-01]])\n",
       "      jac: array([ -1.29877864e-08,  -9.15436295e-07,  -7.66847116e-07])\n",
       "  message: 'Optimization terminated successfully.'\n",
       "     nfev: 22\n",
       "      nit: 16\n",
       "     njev: 22\n",
       "   status: 0\n",
       "  success: True\n",
       "        x: array([-25.16133175,   0.2062317 ,   0.20147159])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost at theta found by optimize: 0.2034977015894421\n",
      "Expected cost (approx):          0.203\n",
      "theta:                           [-25.16133175   0.2062317    0.20147159]\n",
      "Expected theta (approx):         -25.161, 0.206, 0.201\n"
     ]
    }
   ],
   "source": [
    "# Print theta to screen\n",
    "print('Cost at theta found by optimize: %s' % result.fun)\n",
    "print('Expected cost (approx):          0.203')\n",
    "print('theta:                           %s' % result.x)\n",
    "print('Expected theta (approx):         -25.161, 0.206, 0.201')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 1.2.4. Evaluating Logistic Regression\n",
    "Try predicting one student.\n",
    "\n",
    "** Something possibly wrong here **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77629064887795896"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta = result.x\n",
    "X_one = np.array((1, 45, 85))\n",
    "h_one = sigmoid(X_one @ theta)\n",
    "h_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For scores 45 and 85, we predict admission probability 0.776291\n",
      "Expected value: 0.775 +/- 0.002\n"
     ]
    }
   ],
   "source": [
    "# Hmmm.\n",
    "print('For scores 45 and 85, we predict admission probability %f' % h_one)\n",
    "print('Expected value: 0.775 +/- 0.002')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Something definately wrong here **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60999999999999999"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Dohp!\n",
    "probabilities = sigmoid(X @ theta)\n",
    "#predictions = np.where(probabilities >= 0.5, 1.0, 0.0)\n",
    "#predictions = np.round(probabilities) + np.around() # goes to nearest even value, so not exactly the same.\n",
    "predictions = (probabilities >= 0.5).astype(np.float)\n",
    "accuracy = predictions.mean()\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: [61.0]:\n",
      "Expected accuracy (approx): 89.0\n"
     ]
    }
   ],
   "source": [
    "print('Expected accuracy (approx): 89.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
